{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORakMTPK//YiwQquXqk46C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mukil-Git/Synthetic_data_generation/blob/main/Synthetic_data_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kBQTYlO90xov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os"
      ],
      "metadata": {
        "id": "TR9zAcq006Zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(\n",
        "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
        "                )\n",
        "            )\n",
        "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }"
      ],
      "metadata": {
        "id": "9qSM7sT10-vR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SyntheticImageGenerator:\n",
        "    def __init__(self, input_shape=(64, 64, 3), latent_dim=128):\n",
        "        self.input_shape = input_shape\n",
        "        self.latent_dim = latent_dim\n",
        "        self.encoder = None\n",
        "        self.decoder = None\n",
        "        self.vae = None\n",
        "\n",
        "    def build_encoder(self):\n",
        "        \"\"\"Build the encoder network using CNN\"\"\"\n",
        "        encoder_inputs = keras.Input(shape=self.input_shape)\n",
        "\n",
        "        # CNN layers for feature extraction\n",
        "        x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
        "        x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "        x = layers.Conv2D(128, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "        x = layers.Conv2D(256, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "\n",
        "        x = layers.Flatten()(x)\n",
        "        x = layers.Dense(512, activation=\"relu\")(x)\n",
        "\n",
        "        # Latent space parameters\n",
        "        z_mean = layers.Dense(self.latent_dim, name=\"z_mean\")(x)\n",
        "        z_log_var = layers.Dense(self.latent_dim, name=\"z_log_var\")(x)\n",
        "        z = Sampling()([z_mean, z_log_var])\n",
        "\n",
        "        self.encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "        return self.encoder\n"
      ],
      "metadata": {
        "id": "yGvDGP5T1F3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "   def build_decoder(self):\n",
        "        \"\"\"Build the decoder network\"\"\"\n",
        "        latent_inputs = keras.Input(shape=(self.latent_dim,))\n",
        "\n",
        "        # Calculate the shape after flattening in encoder\n",
        "        conv_shape = (4, 4, 256)  # Adjusted based on input_shape and conv layers\n",
        "\n",
        "        x = layers.Dense(np.prod(conv_shape), activation=\"relu\")(latent_inputs)\n",
        "        x = layers.Reshape(conv_shape)(x)\n",
        "\n",
        "        # Transpose convolution layers for upsampling\n",
        "        x = layers.Conv2DTranspose(256, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "        x = layers.Conv2DTranspose(128, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "        x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "        x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Output layer\n",
        "        decoder_outputs = layers.Conv2DTranspose(\n",
        "            self.input_shape[2], 3, activation=\"sigmoid\", padding=\"same\"\n",
        "        )(x)\n",
        "\n",
        "        self.decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "        return self.decoder\n",
        "\n",
        "    def build_vae(self):\n",
        "        \"\"\"Build the complete VAE model\"\"\"\n",
        "        self.build_encoder()\n",
        "        self.build_decoder()\n",
        "        self.vae = VAE(self.encoder, self.decoder)\n",
        "        return self.vae\n",
        "\n",
        "    def preprocess_data(self, images):\n",
        "        \"\"\"Preprocess client data for training\"\"\"\n",
        "        # Normalize pixel values to [0, 1]\n",
        "        images = images.astype(\"float32\") / 255.0\n",
        "\n",
        "        # Resize if needed\n",
        "        if images.shape[1:] != self.input_shape:\n",
        "            images = tf.image.resize(images, self.input_shape[:2])\n",
        "\n",
        "        return images\n",
        ""
      ],
      "metadata": {
        "id": "A3m0Kf3n1UQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  def load_client_data(self, data_path, augment=True):\n",
        "        \"\"\"Load and augment limited client data\"\"\"\n",
        "        # This is a placeholder - adapt based on your client data format\n",
        "        try:\n",
        "            # Example for loading images from directory\n",
        "            if os.path.isdir(data_path):\n",
        "                image_files = [f for f in os.listdir(data_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "                images = []\n",
        "                for file in image_files[:100]:  # Limit for demonstration\n",
        "                    img = keras.preprocessing.image.load_img(\n",
        "                        os.path.join(data_path, file),\n",
        "                        target_size=self.input_shape[:2]\n",
        "                    )\n",
        "                    img_array = keras.preprocessing.image.img_to_array(img)\n",
        "                    images.append(img_array)\n",
        "                images = np.array(images)\n",
        "            else:\n",
        "                # If data_path is a numpy file\n",
        "                images = np.load(data_path)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading data: {e}\")\n",
        "            # Generate synthetic data for demonstration\n",
        "            images = np.random.rand(100, *self.input_shape) * 255\n",
        "\n",
        "        images = self.preprocess_data(images)\n",
        "\n",
        "        # Data augmentation for limited dataset\n",
        "        if augment and len(images) < 1000:\n",
        "            images = self.augment_data(images)\n",
        "\n",
        "        return images\n",
        "\n",
        "    def augment_data(self, images):\n",
        "        \"\"\"Augment limited client data\"\"\"\n",
        "        augmented = []\n",
        "\n",
        "        # Original images\n",
        "        augmented.extend(images)\n",
        "\n",
        "        # Rotations\n",
        "        for angle in [90, 180, 270]:\n",
        "            rotated = tf.image.rot90(images, k=angle//90)\n",
        "            augmented.extend(rotated)\n",
        "\n",
        "        # Horizontal flip\n",
        "        flipped = tf.image.flip_left_right(images)\n",
        "        augmented.extend(flipped)\n",
        "\n",
        "        # Brightness variations\n",
        "        for brightness_delta in [-0.2, 0.2]:\n",
        "            bright = tf.image.adjust_brightness(images, brightness_delta)\n",
        "            bright = tf.clip_by_value(bright, 0.0, 1.0)\n",
        "            augmented.extend(bright)\n",
        "\n",
        "        return np.array(augmented)\n",
        ""
      ],
      "metadata": {
        "id": "khsHEOiG1bI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " def train_model(self, train_data, epochs=100, batch_size=32, validation_split=0.2):\n",
        "        \"\"\"Train the VAE model\"\"\"\n",
        "        if self.vae is None:\n",
        "            self.build_vae()\n",
        "\n",
        "        # Compile model\n",
        "        self.vae.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4))\n",
        "\n",
        "        # Split data\n",
        "        train_images, val_images = train_test_split(\n",
        "            train_data, test_size=validation_split, random_state=42\n",
        "        )\n",
        "\n",
        "        # Callbacks\n",
        "        callbacks = [\n",
        "            keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
        "            keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5),\n",
        "            keras.callbacks.ModelCheckpoint('vae_best.h5', save_best_only=True)\n",
        "        ]\n",
        "\n",
        "        # Train model\n",
        "        history = self.vae.fit(\n",
        "            train_images,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            validation_data=(val_images, val_images),\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        return history\n",
        "\n",
        "    def hyperparameter_tuning(self, train_data):\n",
        "        \"\"\"Perform hyperparameter tuning\"\"\"\n",
        "        best_loss = float('inf')\n",
        "        best_params = {}\n",
        "\n",
        "        # Hyperparameters to tune\n",
        "        latent_dims = [64, 128, 256]\n",
        "        learning_rates = [1e-3, 1e-4, 1e-5]\n",
        "        batch_sizes = [16, 32, 64]\n",
        "\n",
        "        for latent_dim in latent_dims:\n",
        "            for lr in learning_rates:\n",
        "                for batch_size in batch_sizes:\n",
        "                    print(f\"Testing: latent_dim={latent_dim}, lr={lr}, batch_size={batch_size}\")\n",
        "\n",
        "                    # Rebuild model with new parameters\n",
        "                    self.latent_dim = latent_dim\n",
        "                    self.build_vae()\n",
        "                    self.vae.compile(optimizer=keras.optimizers.Adam(learning_rate=lr))\n",
        "\n",
        "                    # Quick training for evaluation\n",
        "                    history = self.vae.fit(\n",
        "                        train_data,\n",
        "                        epochs=10,\n",
        "                        batch_size=batch_size,\n",
        "                        verbose=0\n",
        "                    )\n",
        "\n",
        "                    final_loss = history.history['loss'][-1]\n",
        "\n",
        "                    if final_loss < best_loss:\n",
        "                        best_loss = final_loss\n",
        "                        best_params = {\n",
        "                            'latent_dim': latent_dim,\n",
        "                            'learning_rate': lr,\n",
        "                            'batch_size': batch_size\n",
        "                        }\n",
        "\n",
        "        print(f\"Best parameters: {best_params}\")\n",
        "        print(f\"Best loss: {best_loss}\")\n",
        "\n",
        "        return best_params\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "y6q6tvp91hjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_synthetic_images(self, num_images=10, add_noise=True, noise_factor=0.1):\n",
        "        \"\"\"Generate synthetic images with optional noise\"\"\"\n",
        "        if self.vae is None:\n",
        "            raise ValueError(\"Model not trained yet!\")\n",
        "\n",
        "        # Sample random points in latent space\n",
        "        random_latent_vectors = tf.random.normal(shape=(num_images, self.latent_dim))\n",
        "\n",
        "        # Add noise if requested\n",
        "        if add_noise:\n",
        "            noise = tf.random.normal(shape=random_latent_vectors.shape) * noise_factor\n",
        "            random_latent_vectors += noise\n",
        "\n",
        "        # Generate images\n",
        "        synthetic_images = self.decoder.predict(random_latent_vectors)\n",
        "\n",
        "        return synthetic_images\n",
        "\n",
        "    def interpolate_images(self, img1_idx=0, img2_idx=1, steps=10, source_images=None):\n",
        "        \"\"\"Generate interpolated images between two points in latent space\"\"\"\n",
        "        if source_images is None or len(source_images) < 2:\n",
        "            # Use random latent vectors\n",
        "            z1 = tf.random.normal(shape=(1, self.latent_dim))\n",
        "            z2 = tf.random.normal(shape=(1, self.latent_dim))\n",
        "        else:\n",
        "            # Encode source images to latent space\n",
        "            z1_mean, _, _ = self.encoder.predict(source_images[img1_idx:img1_idx+1])\n",
        "            z2_mean, _, _ = self.encoder.predict(source_images[img2_idx:img2_idx+1])\n",
        "            z1, z2 = z1_mean, z2_mean\n",
        "\n",
        "        # Create interpolation\n",
        "        interpolated_images = []\n",
        "        for i in range(steps):\n",
        "            alpha = i / (steps - 1)\n",
        "            z_interp = (1 - alpha) * z1 + alpha * z2\n",
        "            img = self.decoder.predict(z_interp)\n",
        "            interpolated_images.append(img[0])\n",
        "\n",
        "        return np.array(interpolated_images)\n",
        "\n",
        "    def plot_results(self, original_images, synthetic_images, save_path=None):\n",
        "        \"\"\"Visualize original vs synthetic images\"\"\"\n",
        "        fig, axes = plt.subplots(2, 10, figsize=(20, 4))\n",
        "\n",
        "        # Plot original images\n",
        "        for i in range(min(10, len(original_images))):\n",
        "            axes[0, i].imshow(original_images[i])\n",
        "            axes[0, i].set_title(\"Original\")\n",
        "            axes[0, i].axis('off')\n",
        "\n",
        "        # Plot synthetic images\n",
        "        for i in range(min(10, len(synthetic_images))):\n",
        "            axes[1, i].imshow(synthetic_images[i])\n",
        "            axes[1, i].set_title(\"Synthetic\")\n",
        "            axes[1, i].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        if save_path:\n",
        "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "qrE0CDUW1mGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling(layers.Layer):\n",
        "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "# Main execution example\n",
        "def main():\n",
        "    \"\"\"Main execution pipeline\"\"\"\n",
        "    # Initialize the generator\n",
        "    generator = SyntheticImageGenerator(input_shape=(64, 64, 3), latent_dim=128)\n",
        "\n",
        "    # Load client data (replace with your actual data path)\n",
        "    print(\"Loading client data...\")\n",
        "    client_data = generator.load_client_data(\"path/to/client/data\")  # Update this path\n",
        "    print(f\"Loaded {len(client_data)} images\")\n",
        "\n",
        "    # Optional: Hyperparameter tuning\n",
        "    print(\"Performing hyperparameter tuning...\")\n",
        "    best_params = generator.hyperparameter_tuning(client_data)\n",
        "\n",
        "    # Update model with best parameters\n",
        "    generator.latent_dim = best_params.get('latent_dim', 128)\n",
        "    generator.build_vae()\n",
        "\n",
        "    # Train the model\n",
        "    print(\"Training VAE model...\")\n",
        "    history = generator.train_model(\n",
        "        client_data,\n",
        "        epochs=100,\n",
        "        batch_size=best_params.get('batch_size', 32)\n",
        "    )\n",
        "\n",
        "    # Generate synthetic images\n",
        "    print(\"Generating synthetic images...\")\n",
        "    synthetic_images = generator.generate_synthetic_images(\n",
        "        num_images=50,\n",
        "        add_noise=True,\n",
        "        noise_factor=0.1\n",
        "    )\n",
        "\n",
        "    # Visualize results\n",
        "    generator.plot_results(client_data, synthetic_images, save_path=\"vae_results.png\")\n",
        "\n",
        "    # Save synthetic data\n",
        "    np.save(\"synthetic_images.npy\", synthetic_images)\n",
        "    print(\"Synthetic images saved successfully!\")\n",
        "\n",
        "    return generator, synthetic_images\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generator, synthetic_images = main()"
      ],
      "metadata": {
        "id": "YnK6rWoA1ryq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}